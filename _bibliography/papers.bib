
@misc{tilborghs_comparative_2022,
	title = {Comparative study of deep learning methods for the automatic segmentation of lung, lesion and lesion type in {CT} scans of {COVID}-19 patients},
	url = {http://arxiv.org/abs/2007.15546},
	doi = {10.48550/arXiv.2007.15546},
	abstract = {Recent research on COVID-19 suggests that CT imaging provides useful information to assess disease progression and assist diagnosis, in addition to help understanding the disease. There is an increasing number of studies that propose to use deep learning to provide fast and accurate quantification of COVID-19 using chest CT scans. The main tasks of interest are the automatic segmentation of lung and lung lesions in chest CT scans of confirmed or suspected COVID-19 patients. In this study, we compare twelve deep learning algorithms using a multi-center dataset, including both open-source and in-house developed algorithms. Results show that ensembling different methods can boost the overall test set performance for lung segmentation, binary lesion segmentation and multiclass lesion segmentation, resulting in mean Dice scores of 0.982, 0.724 and 0.469, respectively. The resulting binary lesions were segmented with a mean absolute volume error of 91.3 ml. In general, the task of distinguishing different lesion types was more difficult, with a mean absolute volume difference of 152 ml and mean Dice scores of 0.369 and 0.523 for consolidation and ground glass opacity, respectively. All methods perform binary lesion segmentation with an average volume error that is better than visual assessment by human raters, suggesting these methods are mature enough for a large-scale evaluation for use in clinical practice.},
	urldate = {2025-12-05},
	publisher = {arXiv},
	author = {Tilborghs, Sofie and Dirks, Ine and Fidon, Lucas and Willems, Siri and Eelbode, Tom and Bertels, Jeroen and Ilsen, Bart and Brys, Arne and Dubbeldam, Adriana and Buls, Nico and Gonidakis, Panagiotis and Sánchez, Sebastián Amador and Snoeckx, Annemiek and Parizel, Paul M. and Mey, Johan de and Vandermeulen, Dirk and Vercauteren, Tom and Robben, David and Smeets, Dirk and Maes, Frederik and Vandemeulebroucke, Jef and Suetens, Paul},
	month = jan,
	year = {2022},
	note = {arXiv:2007.15546 [eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	annote = {Comment: Updated acknowledgments},
	selected={true},
	file = {Preprint PDF:C\:\\Users\\u0170095\\Zotero\\storage\\FIHXTV86\\Tilborghs et al. - 2022 - Comparative study of deep learning methods for the automatic segmentation of lung, lesion and lesion.pdf:application/pdf},
}

@misc{berenguer_explainable-by-design_2021,
	title = {Explainable-by-design {Semi}-{Supervised} {Representation} {Learning} for {COVID}-19 {Diagnosis} from {CT} {Imaging}},
	url = {http://arxiv.org/abs/2011.11719},
	doi = {10.48550/arXiv.2011.11719},
	abstract = {Our motivating application is a real-world problem: COVID-19 classification from CT imaging, for which we present an explainable Deep Learning approach based on a semi-supervised classification pipeline that employs variational autoencoders to extract efficient feature embedding. We have optimized the architecture of two different networks for CT images: (i) a novel conditional variational autoencoder (CVAE) with a specific architecture that integrates the class labels inside the encoder layers and uses side information with shared attention layers for the encoder, which make the most of the contextual clues for representation learning, and (ii) a downstream convolutional neural network for supervised classification using the encoder structure of the CVAE. With the explainable classification results, the proposed diagnosis system is very effective for COVID-19 classification. Based on the promising results obtained qualitatively and quantitatively, we envisage a wide deployment of our developed technique in large-scale clinical studies.Code is available at https://git.etrovub.be/AVSP/ct-based-covid-19-diagnostic-tool.git.},
	urldate = {2025-12-05},
	publisher = {arXiv},
	author = {Berenguer, Abel Díaz and Sahli, Hichem and Joukovsky, Boris and Kvasnytsia, Maryna and Dirks, Ine and Alioscha-Perez, Mitchel and Deligiannis, Nikos and Gonidakis, Panagiotis and Sánchez, Sebastián Amador and Brahimetaj, Redona and Papavasileiou, Evgenia and Chana, Jonathan Cheung-Wai and Li, Fei and Song, Shangzhen and Yang, Yixin and Tilborghs, Sofie and Willems, Siri and Eelbode, Tom and Bertels, Jeroen and Vandermeulen, Dirk and Maes, Frederik and Suetens, Paul and Fidon, Lucas and Vercauteren, Tom and Robben, David and Brys, Arne and Smeets, Dirk and Ilsen, Bart and Buls, Nico and Watté, Nina and Mey, Johan de and Snoeckx, Annemiek and Parizel, Paul M. and Guiot, Julien and Deprez, Louis and Meunier, Paul and Gryspeerdt, Stefaan and Smet, Kristof De and Jansen, Bart and Vandemeulebroucke, Jef},
	month = sep,
	year = {2021},
	note = {arXiv:2011.11719 [eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Preprint PDF:C\:\\Users\\u0170095\\Zotero\\storage\\FLS3LSCZ\\Berenguer et al. - 2021 - Explainable-by-design Semi-Supervised Representation Learning for COVID-19 Diagnosis from CT Imaging.pdf:application/pdf},
}

@article{boulogne_stoic2021_2024,
	title = {The {STOIC2021} {COVID}-19 {AI} challenge: applying reusable training methodologies to private data},
	volume = {97},
	shorttitle = {The {STOIC2021} {COVID}-19 {AI} challenge},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841524001555},
	urldate = {2025-12-05},
	journal = {Medical Image Analysis},
	author = {Boulogne, Luuk H. and Lorenz, Julian and Kienzle, Daniel and Schön, Robin and Ludwig, Katja and Lienhart, Rainer and Jégou, Simon and Li, Guang and Chen, Cong and Wang, Qi},
	year = {2024},
	note = {Publisher: Elsevier},
	pages = {103230},
	selected={true},
}

@inproceedings{sonora-mengan_evaluating_2020,
	title = {Evaluating several ways to combine handcrafted features-based system with a deep learning system using the {LUNA16} {Challenge} framework},
	volume = {11314},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11314/113143T/Evaluating-several-ways-to-combine-handcrafted-features-based-system-with/10.1117/12.2549778.short},
	urldate = {2025-12-05},
	booktitle = {Medical {Imaging} 2020: {Computer}-{Aided} {Diagnosis}},
	publisher = {SPIE},
	author = {Sóñora-Mengan, Alexander and Gonidakis, Panagiotis and Jansen, Bart and Garcı́a-Naranjo, Juan and Vandemeulebroucke, Jef},
	year = {2020},
	pages = {900--906},
	file = {Available Version (via Google Scholar):C\:\\Users\\u0170095\\Zotero\\storage\\TMWJ6HYZ\\openurl.html:text/html},
}

@article{gonidakis_handcrafted_2023,
	title = {Handcrafted features can boost performance and data-efficiency for deep detection of lung nodules from {CT} imaging},
	volume = {11},
	url = {https://ieeexplore.ieee.org/abstract/document/10311563/},
	urldate = {2025-12-05},
	journal = {Ieee Access},
	author = {Gonidakis, Panagiotis and Sóñora-Mengana, Alexander and Jansen, Bart and Vandemeulebroucke, Jef},
	year = {2023},
	note = {Publisher: IEEE},
	pages = {126221--126231},
	selected={true},
}

@inproceedings{gonidakis_artificially_2020,
	title = {Artificially augmenting data or adding more samples? {A} study on a {3D} {CNN} for lung nodule classification},
	volume = {11314},
	shorttitle = {Artificially augmenting data or adding more samples?},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11314/113142F/Artificially-augmenting-data-or-adding-more-samples-A-study-on/10.1117/12.2549810.short},
	urldate = {2025-12-05},
	booktitle = {Medical {Imaging} 2020: {Computer}-{Aided} {Diagnosis}},
	publisher = {SPIE},
	author = {Gonidakis, Panagiotis and Jansen, Bart and Vandemeulebroucke, Jef},
	year = {2020},
	pages = {565--570},
	file = {Available Version (via Google Scholar):C\:\\Users\\u0170095\\Zotero\\storage\\BTBV94TK\\openurl.html:text/html},
}

@article{jeong_prediction_2025,
	title = {Prediction of {Time}-evolving {Radial} {Magnetic} {Fields} on the {Solar} {Surface} {Using} {Deep} {Learning}},
	volume = {989},
	url = {https://iopscience.iop.org/article/10.3847/2041-8213/adf5c7/meta},
	number = {2},
	urldate = {2025-12-05},
	journal = {The Astrophysical Journal Letters},
	author = {Jeong, Hyun-Jin and Poedts, Stefaan and Wang, Haopeng and Dineva, Ekatarina and Gonidakis, Panagiotis and Carella, Francesco and Miloshevich, George and Linan, Luis and Lee, Harim},
	year = {2025},
	note = {Publisher: IOP Publishing},
	pages = {L31},
	selected={true},
}

@inproceedings{gonidakis_efficient_2025,
	title = {Efficient {Segmentation} and {Clustering} of {Solar} {Coronal} {Structures}: {A} {Comparison} of {U}-{Net} and {Classical} {Computer} {Vision} {Techniques} {Using} {SDO} {Data}},
	shorttitle = {Efficient {Segmentation} and {Clustering} of {Solar} {Coronal} {Structures}},
	url = {https://ui.adsabs.harvard.edu/abs/2025EGUGA..27.9849G/abstract},
	urldate = {2025-12-05},
	booktitle = {{EGU} {General} {Assembly} {Conference} {Abstracts}},
	author = {Gonidakis, Panagiotis and Carella, Francesco and Miloshevich, George and Poedts, Stefaan},
	year = {2025},
	pages = {EGU25--9849},
}

@inproceedings{torda_machine_2025,
	title = {Machine {Learning} {Algorithms} for {Autonomous} {Space} {Mission} {Operations}},
	url = {https://ui.adsabs.harvard.edu/abs/2025EGUGA..2716713T/abstract},
	urldate = {2025-12-05},
	booktitle = {{EGU} {General} {Assembly} {Conference} {Abstracts}},
	author = {Torda, Tommaso and Alberti, Tommaso and Consolini, Giuseppe and De Marco, Rossana and Dineva, Ekaterina and Ekelund, Jonah and Gonidakis, Panagiotis and Laurenza, Monica and Marcucci, Maria Federica and Markidis, Stefano},
	year = {2025},
	pages = {EGU25--16713},
}

@article{gonidakis_data-and_2024,
	title = {Data-and label-efficient deep learning for medical image analysis: {Application} to lung nodule detection on thoracic {CT}},
	shorttitle = {Data-and label-efficient deep learning for medical image analysis},
	url = {https://researchportal.vub.be/en/publications/data-and-label-efficient-deep-learning-for-medical-image-analysis},
	urldate = {2025-12-05},
	author = {Gonidakis, Panagiotis},
	year = {2024},
}

@article{diaz_berenguer_explainable-by-design_2020,
	title = {Explainable-by-design {Semi}-{Supervised} {Representation} {Learning} for {COVID}-19 {Diagnosis} from {CT} {Imaging}},
	url = {https://ui.adsabs.harvard.edu/abs/2020arXiv201111719D/abstract},
	urldate = {2025-12-05},
	journal = {arXiv e-prints},
	author = {Díaz Berenguer, Abel and Sahli, Hichem and Joukovsky, Boris and Kvasnytsia, Maryna and Dirks, Ine and Alioscha-Perez, Mitchel and Deligiannis, Nikos and Gonidakis, Panagiotis and Amador Sánchez, Sebastián and Brahimetaj, Redona},
	year = {2020},
	pages = {arXiv--2011},
}

@article{gonidakis_computer-aided_2018,
	title = {Computer-{Aided} {Detection} of {Lung} {Nodules} using {Multi}-{Level} {Contextual} {3D} {CNNs}},
	url = {https://researchportal.vub.be/en/publications/computer-aided-detection-of-lung-nodules-using-multi-level-contex},
	urldate = {2025-12-05},
	author = {Gonidakis, Panagiotis and Omelina, Lubos and Jansen, Bart and Vandemeulebroucke, Jef},
	year = {2018},
}

@inproceedings{chapman_fossil_2018,
	title = {Fossil hominids on the move: new developments in fossil hominid biomechanical analysis.},
	shorttitle = {Fossil hominids on the move},
	url = {https://hal.science/hal-02853368/},
	urldate = {2025-12-05},
	booktitle = {{ESHE} meeting},
	author = {Chapman, T. and van Sint Jan, S. and Sholukha, V. and Gonidakis, P. and Jansen, B. and Balzeau, Antoine and Polet, C. and Cammaert, L. and Louryan, S. and Semal, P.},
	year = {2018},
}
